XLag=cbind(Lag1,Lag2)
train = Year < 2005
XLag[1:5,]
knn.pred = knn(XLag[train,], XLag[!train,], Direction[train], k = 1)
table(knn.pred, Direction[!train])
mean(knn.pred == Direction[!train])
knn.pred = knn(XLag[train,], XLag[!train,], Direction[train], k = 3)
table(knn.pred, Direction[!train])
mean(knn.pred == Direction[!train])
require(ISLR)
require(boot)
?cv.glm
plot(mpg~horsepower,data=Auto)
load(autos)
names(auto)
names(autos)
names(Auto)
plot(mpg~horsepower,data=Auto)
plot(mpg~hp,data=Auto)
glm.fit = glm(mpg~hp, data = Auto)
cv.glm(Auto,glm.fit)$delta
loocv(glm.fit)
loocv = function(fit){
h = lm.influence(fit)$h
mean(residuals(fit)/(1-h))^2)
}
## Now we try it out
loocv(glm.fit)
loocv = function(fit){
h = lm.influence(fit)$h
mean((residuals(fit)/(1-h))^2)
}
loocv(glm.fit)
cv.error = rep(0,5)
degree=1:5
for(d in degree){
glm.fit=glm(mpg~poly(hp,d), data=Auto)
cv.error[d]=loocv(glm.fit)
}
plot(degree, cv.error, type="b")
for(d in degree){
glm.fit = glm(mpg~hp,d), data=Auto)
cv.error10[d] = cv.glm(Auto, glm.fit, k = 10)$delta[1]
}
for(d in degree){
glm.fit = glm(mpg~poly(hp,d), data=Auto)
cv.error10[d] = cv.glm(Auto, glm.fit, k = 10)$delta[1]
}
for(d in degree){
glm.fit = glm(mpg~poly(hp,d), data=Auto)
cv.error10[d] = cv.glm(Auto, glm.fit, K = 10)$delta[1]
}
cv.error10 = rep(0,5)
for(d in degree){
glm.fit = glm(mpg~poly(hp,d), data=Auto)
cv.error10[d] = cv.glm(Auto, glm.fit, K = 10)$delta[1]
}
cv.error10 = rep(0,5)
for(d in degree){
glm.fit = glm(mpg~poly(hp,d), data=Auto)
cv.error10[d] = cv.glm(Auto, glm.fit, K = 10)$delta[1]
}
lines(degree, cv.error10, type = "b", col = "red")
?var
alpha = function(x,y){
vx = var(x)
vy = var(y)
cxy = cov(x,y)
(vy - cxy)/(vx+vy-2*cxy)
}
alpha(Portfolio$X,Portfolio$Y)
alpha.fn=function(data, index){
with(data[index,],alpha(X,Y))
}
alpha.fn(Portfolio,1:100)
set.seed(1)
alpha.fn(Portfolio,sample(1:100,100,replace = TRUE))
boot.out = boot(Portfolio,alpha.fn,R=1000)
boot.out
plot(boot.out)
load("5.R.RData")
names(Xy)
lm.fit = lm(y~X1+X2, data = Xy)
summary(lm.fit)
matplot(Xy,type="I")
matplot(Xy,type="i")
matplot(Xy,type="l")
?boot
boot.out = boot(Xy, lm(y~.,data=Xy), R=1000)
boot.out = boot(Xy, lm, R=1000)
boot.out = boot(Xy, lm.fit, R=1000)
boot.out = boot(Xy, alpha.fn, R=1000)
alpha.fn = function(data, index){
with(data[index,],lm(y~X1+X2,data = Xy))
}
boot.out = boot(Xy, alpha.fn, R=1000)
alpha.fn(Xy,1:100)
alpha.fn(Xy,1:10)
alpha.fn(Xy,1)
alpha = function(x,y){
vx = var(x)
vy = var(y)
cxy = cov(x,y)
(vy - cxy)/(vx+vy-2*cxy)
}
alpha(Portfolio$X,Portfolio$Y)
alpha.fn=function(data, index){
with(data[index,],alpha(X,Y))
}
alpha.fn(Portfolio,1:100)
alpha.fn = function(data, index){
with(data[index,],lm(y~X1+X2,data = Xy))
}
alpha.fn(Xy,sample(1:100,100,replace = TRUE))
alpha.fn(Xy,sample(1:100,100,replace = TRUE))
boot.out = boot(Xy, alpha.fn, R=1000)
summary(alpha.fn(Xy,sample(1:100,100,replace = TRUE)))
?lm
lm(y~X1+X2,data = Xy).coefficients
lm(y~X1+X2,data = Xy)$coefficients
alpha.fn = function(data, index){
with(data[index,],lm(y~X1+X2,data = Xy)$coefficients)
}
boot.out = boot(Xy, alpha.fn, R=1000)
boot.out
alpha.fn(Xy,1)
summary(alpha.fn(Xy,sample(1:100,100,replace = TRUE)))
?boot
alpha(Portfolio$X,Portfolio$Y)
lm(y~X1+X2,data = Xy)$coefficients
lm(y~X1+X2,data = Xy)$coefficients[1]
lm(y~X1+X2,data = Xy)$coefficients[2]
alpha.fn = function(data, index){
with(data[index,],lm(y~X1+X2,data = Xy)$coefficients[2])
}
boot.out = boot(Xy, alpha.fn, R=1000)
boot.out
alpha.fn = function(data, index){
with(data[index,],lm(y~X1+X2)$coefficients[2])
}
boot.out = boot(Xy, alpha.fn, R=1000)
boot.out
alpha.fn = function(data, index){
with(data[index,],lm(y~X1+X2)$coefficients)
}
#lm(y~X1+X2,data = Xy)$coefficients[2]
boot.out = boot(Xy, alpha.fn, R=1000)
boot.out
alpha.fn = function(data, index){
data = data[index,]
lm(y~X1+X2, data = data)$coefficients
}
#lm(y~X1+X2,data = Xy)$coefficients[2]
boot.out = boot(Xy, alpha.fn, R=1000)
boot.out
boot.out = boot(Xy, alpha.fn, R=999)
boot.out
lm(y~X1+X2,data = Xy)$coefficients[2]
lm(y~X1+X2,data = Xy)$coefficients
alpha.fn = function(data, index){
data = data[index,]
lm(y~X1+X2, data = data)$coefficients[2]
}
boot.out = boot(Xy, alpha.fn, R=999)
boot.out
lm(y~X1+X2,data = Xy)$coefficients
summary(lm(y~X1+X2,data = Xy))
boot.out = boot(Xy, alpha.fn, R=2000)
boot.out
new.Xy = c(Xy[0:100], Xy[101:200], Xy[201:300], Xy[301:400], Xy[401:500], Xy[501:600], Xy[601:700],Xy[701:800], Xy[801:900], Xy[901:1000])
str(new.Xy)
new.Xy = c(Xy[0:100,], Xy[101:200,], Xy[201:300,], Xy[301:400,], Xy[401:500,], Xy[501:600,], Xy[601:700,],Xy[701:800,], Xy[801:900,], Xy[901:1000,])
str(new.Xy)
dim(new.Xy)
summary(new.Xy)
new.Xy
str(Xy)
type(Xy)
typeof(Xy)
Xy
boot.out = boot(new.Xy, alpha.fn, R=2000)
require(ISLR)
require(boot)
require(ISLR)
require(boot)
?cv.glm
names(Auto)
plot(mpg~hp,data=Auto)
## LOOCV
glm.fit = glm(mpg~hp, data = Auto)
cv.glm(Auto,glm.fit)$delta
##Lets write a simple function to use formula (5.2)
loocv = function(fit){
h = lm.influence(fit)$h
mean((residuals(fit)/(1-h))^2)
}
## Now we try it out
loocv(glm.fit)
cv.error = rep(0,5)
degree=1:5
for(d in degree){
glm.fit=glm(mpg~poly(hp,d), data=Auto)
cv.error[d]=loocv(glm.fit)
}
plot(degree, cv.error, type="b")
## 10-fold CV
cv.error10 = rep(0,5)
for(d in degree){
glm.fit = glm(mpg~poly(hp,d), data=Auto)
cv.error10[d] = cv.glm(Auto, glm.fit, K = 10)$delta[1]
}
lines(degree, cv.error10, type = "b", col = "red")
##Bootstrap
## Minimum risk investment
alpha = function(x,y){
vx = var(x)
vy = var(y)
cxy = cov(x,y)
(vy - cxy)/(vx+vy-2*cxy)
}
alpha(Portfolio$X,Portfolio$Y)
## What is the standard error of alpha?
alpha.fn=function(data, index){
with(data[index,],alpha(X,Y))
}
alpha.fn(Portfolio,1:100)
set.seed(1)
alpha.fn(Portfolio,sample(1:100,100,replace = TRUE))
boot.out = boot(Portfolio,alpha.fn,R=1000)
boot.out
plot(boot.out)
```
##Chapter 5 Quiz
***
```{r echo = FALSE}
## To within 10%, what is the standard error for β1?
load("5.R.RData")
names(Xy)
lm.fit = lm(y~X1+X2, data = Xy)
summary(lm.fit)
matplot(Xy,type="l")
## Now, use the (standard) bootstrap to estimate s.e.(β̂ 1). To within 10%, what do you get?
alpha.fn = function(data, index){
data = data[index,]
lm(y~X1+X2, data = data)$coefficients[2]
}
summary(lm(y~X1+X2,data = Xy))
boot.out = boot(Xy, alpha.fn, R=2000)
boot.out
## Finally, use the block bootstrap to estimate s.e.(β̂ 1). Use blocks of 100 contiguous observations, and resample ten whole blocks with replacement then paste them together to construct each bootstrap time series.
new.Xy = c(Xy[0:100,], Xy[101:200,], Xy[201:300,], Xy[301:400,], Xy[401:500,], Xy[501:600,], Xy[601:700,],Xy[701:800,], Xy[801:900,], Xy[901:1000,])
#new.Xy
boot.out = boot(new.Xy, alpha.fn, R=2000)
boot.out
new.Xy.index
new.Xy.index()
new.Xy.indices
new.Xy.indices()
new.Xy[1]
Xy[1]
new.Xy = c(Xy[0:100,:], Xy[101:200,:], Xy[201:300,:], Xy[301:400,:], Xy[401:500,:], Xy[501:600,:], Xy[601:700,:],Xy[701:800,:], Xy[801:900,:], Xy[901:1000,:])
Xy[0:100,]
c(Xy[0:100,],Xy[101:200,])
?boot
boot.out = boot(new.Xy, alpha.fn, R=2000)
dim(new.Xy)
dim(c(Xy[0:100,],Xy[101:200,]))
dim(Xy)
alpha.fn = function(data, index){
data = data[index,]
d = Xy[data,]
lm(y~X1+X2, data = d)$coefficients[2]
}
boot.out = boot(new.Xy, alpha.fn, R=2000)
new.Xy = c(Xy[0:100,], Xy[101:200,], Xy[201:300,], Xy[301:400,], Xy[401:500,], Xy[501:600,], Xy[601:700,],Xy[701:800,], Xy[801:900,], Xy[901:1000,])
alpha.fn = function(data, index){
data = data[index,]
d = Xy[data,]
lm(y~X1+X2, data = d)$coefficients[2]
}
boot.out = boot(new.Xy, alpha.fn, R=2000)
new.Xy[1,2]
new.Xy[1,2,]
new.Xy[1]
new.Xy = c(0:100, 101:200, 201:300, 301:400, 401:500, 501:600, 601:700,701:800, 801:900, 901:1000)
new.Xy[1]
new.Xy[1,2]
new.Xy = c(0:100, 101:200, 201:300, 301:400, 401:500, 501:600, 601:700,701:800, 801:900, 901:1000)
new.Xy = c([0:100], [101:200], [201:300], [301:400], [401:500], [501:600], [601:700],[701:800], [801:900], [901:1000])
new.Xy = c( [0:100], [101:200], [201:300], [301:400], [401:500], [501:600], [601:700],[701:800], [801:900], [901:1000])
new.Xy = c( c(0:100), c(101:200), c(201:300), c(301:400), c(401:500), c(501:600), c(601:700),c(701:800), c(801:900), c(901:1000))
new.Xy[1,2]
new.Xy[1]
new.Xy[[1]]
dim(new.Xy)
0:100
c(0:100,101:200)
[0:100]
I[0:100]
I(0:100)
new.Xy = list(c(0:100), c(101:200), c(201:300), c(301:400), c(401:500), c(501:600), c(601:700),c(701:800), c(801:900), c(901:1000))
new.Xy[[1]]
new.Xy[[1,2]]
new.Xy[1]
new.Xy[1,2]
new.Xy[1:2]
new.Xy[[3,2,2]]
dim(new.Xy)
?vector
new.Xy[1]
new.Xy[2]
new.Xy[3]
new.Xy[1,2,3]
new.Xy[c(1,2,3)]
alpha.fn = function(data, index){
data = data[index,]
d = Xy[data,]
lm(y~X1+X2, data = d)$coefficients[2]
}
boot.out = boot(new.Xy, alpha.fn, R=2000)
new.Xy[c(1,2,3),]
alpha.fn = function(data, index){
data = data[index]
d = Xy[data,]
lm(y~X1+X2, data = d)$coefficients[2]
}
boot.out = boot(new.Xy, alpha.fn, R=2000)
new.Xy[c(1,2,3)]
new.Xy[c(1,2,3)]
alpha.fn = function(data, index){
data = data[index]
d = Xy[rbind(data),]
lm(y~X1+X2, data = d)$coefficients[2]
}
boot.out = boot(new.Xy, alpha.fn, R=2000)
rbind(new.Xy[c(1,2,3)])
new.Xy[c(1,2,3)]
as.vector(new.Xy[c(1,2,3)])
c(new.Xy[c(1,2,3)])
unlist(new.Xy[c(1,2,3)])
alpha.fn = function(data, index){
data = data[index]
d = Xy[unlist(data),]
lm(y~X1+X2, data = d)$coefficients[2]
}
boot.out = boot(new.Xy, alpha.fn, R=2000)
boot.out
library(ISLR)
summary(Hitters)
Hitters=na.omit(Hitters)
with(Hitters, sum(is.na(Salary)))
library(leaps)
install.packages("leaps")
library(leaps)
regfit.full = regsubsets(Salary~.,data=Hitters)
summary(regfit.full)
regfit.full=regsubsets(Salary~.,data=Hitters, nvmax=19)
reg.summary =  summary(regfit.full)
names(reg.summary)
plot(reg.summary$cp, xlab="number of Variables", ylab="Cp")
which.min(reg.summary$cp)
points(10,reg.summary$cp[10],pch=20,col="red")
plot(regfit.full,scale="Cp")
coef(regfit.full,10)
regfit.fwd = regsubsets(Salary~., data = Hitters, nvmax = 19, method = "forward")
summary(regfit.fwd)
plot(regfit.fwd, scale = "Cp")
dim(Hitters)
set.seed(1)
train = sample(seq(263),10,replace=FALSE)
train = sample(seq(263),180,replace=FALSE)
train
dim(Hitters)
set.seed(1)
train = sample(seq(263),180,replace=FALSE)
train
regfit.fwd = regsubsets(Salary~.,data=Hitters[train,], nvmax=19, method = "forward")
val.errors=rep(NA,19)
x.test=model.matrix(Salary~., data=Hitters[-train,])
for(i in 1:19){
coefi = coef(regfit.fwd, id = i)
pred = x.test[,names(coefi)]%*%coefi
val.errors[i]=mean((Hitters$Salary[-train]-pred)^2)
}
plot(sqrt(val.errors), ylab="Root MSE", ylim=c(300,400), pch=19, type="b")
points(sqrt(regfit.fwd$rss[-1]/180), col="blue", pch=19,type="b")
legend("topright", legend=c("Training", "Validation"), col=c("blue","black"),pch=19)
predict.regsubsets=function(object, newdata,id,...){
form=as.formula(objects$call[[2]])
mat = model.matrix(form, newdata)
coefi=coef(object,id=id)
mat[,names(coefi)]%*%coefi
}
set.seed(11)
folds = sample(rep(1:10, length=nrow(Hitters)))
folds
table(folds)
cv.errors = matrix(NA,10,19) # make matrix for our errors
set.seed(11)
folds = sample(rep(1:10, length=nrow(Hitters)))
folds
table(folds)
cv.errors = matrix(NA,10,19) # make matrix for our errors
for(k in 1:10){
best.fit=regsubsets(Salary~., data = Hitters[folds !=k, ], nvmax=19, method="forward")
for(i in 1:19){
pred = predict(best.fit, Hitters[folds ==k,], id=i)
cv.errors[k,i] = mean( (Hitters$Salary[folds==k] - pred)^2)
}
}
predict.regsubsets=function(object, newdata,id,...){
form=as.formula(objects$call[[2]])
mat = model.matrix(form, newdata)
coefi=coef(object,id=id)
mat[,names(coefi)]%*%coefi
}
set.seed(11)
folds = sample(rep(1:10, length=nrow(Hitters)))
folds
table(folds)
cv.errors = matrix(NA,10,19) # make matrix for our errors
for(k in 1:10){
best.fit=regsubsets(Salary~., data = Hitters[folds !=k, ], nvmax=19, method="forward")
for(i in 1:19){
pred = predict(best.fit, Hitters[folds ==k,], id=i)
cv.errors[k,i] = mean( (Hitters$Salary[folds==k] - pred)^2)
}
}
set.seed(11)
folds = sample(rep(1:10, length=nrow(Hitters)))
folds
table(folds)
cv.errors = matrix(NA,10,19) # make matrix for our errors
for(k in 1:10){
best.fit=regsubsets(Salary~., data = Hitters[folds!=k,], nvmax=19, method="forward")
for(i in 1:19){
pred = predict(best.fit, Hitters[folds==k,], id=i)
cv.errors[k,i] = mean( (Hitters$Salary[folds==k] - pred)^2)
}
}
rmse.cv = sqrt(apply(cv.errors,2,mean))
plot(rmse.cv,pch=19,type="b")
best.fit=regsubsets(Salary~., data=Hitters[folds!=k,], nvmax=19, method="forward")
pred = predict(best.fit, Hitters[folds==k,], id=i)
predict.regsubsets=function(object, newdata,id,...){
form=as.formula(object$call[[2]])
mat = model.matrix(form, newdata)
coefi=coef(object,id=id)
mat[,names(coefi)]%*%coefi
}
set.seed(11)
folds = sample(rep(1:10, length=nrow(Hitters)))
folds
table(folds)
cv.errors = matrix(NA,10,19) # make matrix for our errors
for(k in 1:10){
best.fit=regsubsets(Salary~., data=Hitters[folds!=k,], nvmax=19, method="forward")
for(i in 1:19){
pred = predict(best.fit, Hitters[folds==k,], id=i)
cv.errors[k,i] = mean( (Hitters$Salary[folds==k] - pred)^2)
}
}
rmse.cv = sqrt(apply(cv.errors,2,mean))
plot(rmse.cv,pch=19,type="b")
library(glmnet)
x = model.matrix(Salary~., data = Hitters)
y = Hitters$Salary
install.packages(glmnet)
library(glmnet)
install.packages("glmnet", repos = "http://cran.us.r-project.org")
library(glmnet)
x = model.matrix(Salary~., data = Hitters)
y = Hitters$Salary
fit.ridge = glmnet(x,y,alpha=0) # 0 ridge 1 lasso.
plot(fit.ridge,xvar="lambda", label=TRUE)
cv.ridge=cv.glmnet(x,y,alpha=0)
plot(cv.ridge)
fit.lasso=glmnet(x,y)
plot(fit.lasso,xvar='lambda', label-TRUE)
plot(fit.lasso, xvar="lambda", label-TRUE)
fit.lasso=glmnet(x,y)
plot(fit.lasso, xvar="lambda", label-TRUE)
cv.lasso=cv.glmnet(x,y)
plot(fit.lasso, xvar="lambda", label=TRUE)
plot(cv.lasso)
coef(cv.lasso)
lasso.tr=glmnet(x[train,],y[train])
lasso.tr
pred=predict(lasso.tr,x[-train,])
dim(pred)
rmse = sqrt(apply((y[-train]-pred)^2,2,mean)) # y is broadcast to the dimension of pred
plot(log(lasso.tr$lambda), rmse, type="b", xlab="Log(lambda)")
lam.best = lasso.tr$lambda[order(rmse)[1]]
lam.best
coef(lasso.tr, s = lam.best)
?cv.glmnet()
?gam
??gam
?GAM
require(ISLR)
attach(wage)
require(ISLR)
attach(Wage)
fit = lm(wage~poly(age,4),data=Wage)
summary(fit)
agelims=range(age)
age.grid = seq(from=agelims[1], to=agelims[2])
preds=predict(fit,newdata=list(age=age.grid), se=TRUE)
se.bands = cbind(preds$fit+2*preds$se,preds$fit-2*preds$se)
plot(age,wage,col='darkgrey')
lines(age.grid,preds$fit, lwd=2, col="blue")
matlines(age.grid, se.bands, col="blue",lty=2)
